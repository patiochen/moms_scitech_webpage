<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MOMS Project Page</title>

    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;700;800&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/swiper@11/swiper-bundle.min.css" />
    <link rel="stylesheet" href="style.css">
</head>

<body>

    <div class="container">

        <h1 class="title">
            Simultaneous Track-Monitoring of Multiple Mobile Airspace Objects<br>
            Using Non-Collocated Video Sensors
        </h1>

        <div class="authors">
            <p>Chenyan Zhu</p>
        </div>

        <div class="affiliations">
            <p>Department of Electrical & Computer Engineering</p>  <p>Texas A&amp;M University, College Station, TX</p>  <p class="venue">2026 AIAA SciTech</p>
        </div>

        <div class="buttons">
            <a class="btn" href="paper.pdf" target="_blank">
                <i class="fa-regular fa-file-pdf"></i> Paper
            </a>
            <a class="btn" href="https://arxiv.org" target="_blank">
                <i class="fa-solid fa-file-lines"></i> arXiv
            </a>
            <a class="btn" href="https://youtube.com" target="_blank">
                <i class="fa-brands fa-youtube"></i> Video
            </a>
            <a class="btn" href="https://github.com/yourname/yourrepo" target="_blank">
                <i class="fa-brands fa-github"></i> Code
            </a>
            <a class="btn" href="data.zip" target="_blank">
                <i class="fa-solid fa-database"></i> Data
            </a>
        </div>

        <div class="video-wrapper">
            <video
                controls
                autoplay
                loop
                muted
                playsinline
                class="demo-video">
                <source src="Video/detetcion.mp4" type="video/mp4">
                您的浏览器不支持 HTML5 视频。
            </video>
        </div>

    </div> <section class="abstract-block">
        <div class="abstract-section">
            <h2 class="abstract-title">Abstract</h2>
            <p class="abstract-text">
                As dense uncrewed aircraft system (UAS) operations become more prevalent, there is a growing need for ground-based monitoring of multiple heterogeneous airspace objects (including UASs, crewed aircraft, birds, and projectiles) in airspace volumes. Monitoring needs in these settings are often track- (trajectory-) centered, encompassing: 1) fast detection of objects that impinge on the airspace, 2) recording and differentiation of multiple object tracks in sensing data, 3) matching and location of the tracks in geographical coordinates using multiple sensors, and 4) real-time alarming of object conflicts and other scenarios of concern. This article reports on a distributed system for real-time track-based monitoring of multiple mobile airspace objects, which uses video cameras arranged in two or more non-collocated pods for monitoring. The distributed architecture of the monitoring system is described, and the methods/algorithms used for comprehensive track monitoring are developed. Multi-track monitoring is demonstrated in the scope of two flight campaigns involving multi-UAS operations, conducted near Fairbanks, Alaska, as well as demonstrations in Langley, Virginia and College Station, TX.
            </p>
        </div>
    </section>

    <section class="carousel-section">
      <div class="swiper-container">
        <div class="swiper-wrapper">

          <div class="swiper-slide">
            <img src="figs/classification.png" alt="Image 1">
          </div>
          <div class="swiper-slide">
            <img src="figs/traj.png" alt="Image 2">
          </div>
          <div class="swiper-slide">
            <img src="figs/3d.png" alt="Image 3">
          </div>

        </div>

        <!-- 分页圆点 -->
        <div class="swiper-pagination"></div>

        <!-- 左右按钮 -->
        <div class="swiper-button-prev"></div>
        <div class="swiper-button-next"></div>
      </div>
    </section>


    <section class="gray-section">
      <div class="section-header">
        <h2>Architecture and Hardware</h2>
      </div>

      <div class="section-content">
        <img src="figs/network.png" alt="Hardware Layout" class="section-img">
        <p>
          The architecture includes distributed Raspberry Pi pods connected via low-latency TCP sockets.
          Each pod consists of a high-resolution camera and edge-processing unit optimized for trajectory extraction.
        </p>

        <img src="figs/edgedevice.png" alt="Hardware Layout" class="section-img">
        <p>
          The architecture includes distributed Raspberry Pi pods connected via low-latency TCP sockets.
          Each pod consists of a high-resolution camera and edge-processing unit optimized for trajectory extraction.
        </p>
      </div>
    </section>


    <!-- ======= Sensor Deployment Section ======= -->
    <section class="white-section">
      <div class="section-header">
        <h2>Algorithm Suite</h2>
      </div>

      <div class="section-content row-layout">
        <div class="image-col">
          <img src="figs/algorithm.png" alt="Sensor Deployment Map" class="section-img">
        </div>
        <div class="text-col">
          <p>
            The deployment strategy places sensor pods along known UAV traffic corridors, ensuring overlapping field-of-view coverage. Each pod operates independently and communicates via local mesh networks to a central processing node.
          </p>
        </div>
      </div>
    </section>

    <section class="citation-section">
      <div class="section-header">
        <h2>BibTeX</h2>
      </div>

      <div class="bibtex-block">
    <pre><code>@InProceedings{Zhu_2026_SciTech,
      author    = {Zhu, Chenyan and Others},
      title     = {Track-Vision: Real-Time Multi-Object Monitoring Using Non-Collocated Video Sensors},
      booktitle = {AIAA SciTech Forum},
      month     = {January},
      year      = {2026},
      pages     = {TBD}
    }</code></pre>
      </div>

      <p class="credits">
        System implementation, flight campaign data, and animations were developed by Chenyan Zhu and collaborators.<br>
        For questions, contact: <a href="mailto:chenyan.zhu@tamu.edu">chenyan.zhu@tamu.edu</a>
      </p>
    </section>



<!-- Swiper 样式和脚本 -->
    <script src="https://cdn.jsdelivr.net/npm/swiper@11/swiper-bundle.min.js"></script>

    <!-- 初始化脚本 -->
    <script>
      const swiper = new Swiper('.swiper-container', {
        loop: true,
        spaceBetween: 40,
        pagination: {
          el: '.swiper-pagination',
          clickable: true,
        },
        navigation: {
          nextEl: '.swiper-button-next',
          prevEl: '.swiper-button-prev',
        },
      });
    </script>

</body>
</html>